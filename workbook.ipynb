{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Significant Flight Delays using Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I present my work in predicting flight delays by use of supervised learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many consultants travel frequently over long distances for business purposes. Managers at a consulting firm might be interested in how to minimize risk when booking flights. One pertinent concern for these managers is how to reduce the risk of significant flight delay to ensure that consultants can utilize air travel reliably and efficiently.\n",
    "\n",
    "My goal is to predict whether a given flight will be significantly delayed given several known factors about the flight such as time of year, airline, time of departure, and other significant factors. An effective model of this kind will assist managers in understanding potential risks so that they can make more informed decisions when booking flights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* Descriptive statistics\n",
    "* Justification of inclusion of features (?)\n",
    "* Limitations of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I obtained data for use by the public domain from https://www.kaggle.com/datasets/robikscube/flight-delay-dataset-20182022 containing flight data spanning between 2018 and 2022. Each row pertains to a flight and includes several features such as time of year, airline, origin/destination airports, departure/arrival time blocks, and distance, among others. This data will provide an abundance of flights to build our model from as well as several promising features to use as predictors.\n",
    "\n",
    "I will bulid my model using a random sample of 100,000 flights from a year's worth of raw data spanning from August 2021 to July 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nnetznik\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3145: DtypeWarning: Columns (12,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df_original = pd.read_csv('sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be selecting features that would be known prior to a flight's departure and that could provide useful information for predicting delays. We will be excluding features that would not be known prior to takeoff, as well as identifiers with no interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = ['Quarter',\n",
    "           'Month', 'DayOfWeek', 'Operating_Airline ',\n",
    "           'Origin', 'Dest',\n",
    "           'DepTimeBlk', 'ArrDel15', 'ArrTimeBlk', 'Cancelled', 'Distance']\n",
    "\n",
    "df = df_original[to_keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our target variable will be a binary indicator that yields 1 if a flight is delayed by at least 15 minutes or cancelled, and yields 0 otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-67ae4c08d16f>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Target'] = 0\n",
      "C:\\Users\\nnetznik\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "df['Target'] = 0\n",
    "for idx, row in df.iterrows():\n",
    "    if row['ArrDel15'] == 1 or row['Cancelled'] == 1:\n",
    "        df.at[idx, 'Target'] = 1\n",
    "df.drop(['ArrDel15','Cancelled'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As most of our predictors are categorical, we will apply one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "X = df.drop(['Target'], axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "X_cat = X.drop(['Distance'], axis=1)\n",
    "X_num = X[['Distance']]\n",
    "\n",
    "ohe = OneHotEncoder(drop=\"first\", sparse=False)\n",
    "ohe.fit(X_cat)\n",
    "\n",
    "X_cat_ohe = pd.DataFrame(\n",
    "    data=ohe.transform(X_cat),\n",
    "    index=X_cat.index\n",
    ")\n",
    "\n",
    "X_final = pd.concat([X_num, X_cat_ohe], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use 75% of our data for training and 25% of our data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will evaluate each model using an accuracy score for training and testing predictions. We will also use a confusion matrix and related statistics for the training predictions. In particular, we will calculate:\n",
    "\n",
    "* Percentage of predicted delays/cancellations that were delayed/cancelled\n",
    "* Percentage of predicted non-delays/cancellations that were not delayed/cancelled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def get_metrics(y_train, y_train_pred, y_test, y_test_pred, c):\n",
    "    print('Train accuracy: ', accuracy_score(y_train, y_train_pred))\n",
    "    print('Test accuracy: ', accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "    tn = c[0][0]\n",
    "    fp = c[0][1]\n",
    "    fn = c[1][0]\n",
    "    tp = c[1][1]\n",
    "    \n",
    "    print()\n",
    "    print(\"TN: {}\\tFP:{}\\nFN: {}\\tTP: {}\".format(tn, fp, fn, tp))\n",
    "    print()\n",
    "    \n",
    "    print(\"% Predicted delays/cancellations that were delayed/cancelled: {}\".format(tp/(tp+fp)))\n",
    "    print(\"% Predicted non-delays/cancellations that were not delayed/cancelled: {}\".format(tn/(tn+fn)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our initial model will be a simple decision tree model with default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9952\n",
      "Test accuracy:  0.69172\n",
      "\n",
      "TN: 15734\tFP:3742\n",
      "FN: 3965\tTP: 1559\n",
      "\n",
      "% Predicted delays/cancellations that were delayed/cancelled: 0.2940954536879834\n",
      "% Predicted non-delays/cancellations that were not delayed/cancelled: 0.7987207472460531\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=100)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf.predict(X_train)\n",
    "y_test_pred = clf.predict(X_test)\n",
    "c = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "get_metrics(y_train, y_train_pred, y_test, y_test_pred, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few observations: \n",
    "* Our model appears to be overfit, as training accuracy is significantly higher than testing accuracy.\n",
    "* Of the positive (delayed/cancelled) predictions that we make, few are actually correct.\n",
    "* Most of our negative (non-delayed/cancelled) predictions are correct.\n",
    "\n",
    "We will make a few adjustments to the previous model:\n",
    "1. We will conduct a grid search on various model parameters to optimize it. In particular, we will optimize our model with respect to its F1 score, which is designed to balance false positives and false negatives to yield a good \"overall\" fit.\n",
    "2. We will utilize the *class_weight='balanced'* parameter. This is because we believe that class imbalance is contributing to our low metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# clf_grid = DecisionTreeClassifier()\n",
    "\n",
    "# param_grid = {\n",
    "#     'criterion': ['gini', 'entropy'],\n",
    "#     'max_depth': [5, 10, 20],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [2, 5, 10],\n",
    "#     'class_weight':['balanced']\n",
    "# }\n",
    "\n",
    "# gs_tree = GridSearchCV(clf_grid, param_grid, cv=3, scoring='f1')\n",
    "# gs_tree.fit(X_train, y_train)\n",
    "\n",
    "# gs_tree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.5462266666666666\n",
      "Test accuracy:  0.53132\n",
      "\n",
      "TN: 9534\tFP:9942\n",
      "FN: 1775\tTP: 3749\n",
      "\n",
      "% Predicted delays/cancellations that were delayed/cancelled: 0.2738295230443357\n",
      "% Predicted non-delays/cancellations that were not delayed/cancelled: 0.8430453621009815\n"
     ]
    }
   ],
   "source": [
    "clf_best = DecisionTreeClassifier(criterion='entropy', max_depth=10, min_samples_split=10, min_samples_leaf=2, class_weight='balanced', random_state=100)\n",
    "clf_best.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = clf_best.predict(X_train)\n",
    "y_test_pred = clf_best.predict(X_test)\n",
    "c = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "get_metrics(y_train, y_train_pred, y_test, y_test_pred, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* Our training and testing accuracy went down, but are roughly equal - we have solved the issue of overfitting.\n",
    "* Our predicted delays/cancellations are still very inaccurate.\n",
    "* Our negative predictions are slightly more accurate.\n",
    "\n",
    "To further improve upon the model, we will instead use a random forest classifier built from several decision trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# rfc_grid = RandomForestClassifier()\n",
    "\n",
    "# param_grid_rfc = {\n",
    "#     'n_estimators':[10],\n",
    "#     'criterion': ['gini', 'entropy'],\n",
    "#     'max_depth': [5, 10, 20],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [2, 5, 10],\n",
    "#     'class_weight':['balanced']\n",
    "# }\n",
    "\n",
    "# gs_rfc_tree = GridSearchCV(rfc_grid, param_grid_rfc, cv=3, scoring='f1')\n",
    "# gs_rfc_tree.fit(X_train, y_train)\n",
    "\n",
    "# gs_rfc_tree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6293466666666667\n",
      "Test accuracy:  0.61344\n",
      "\n",
      "TN: 12023\tFP:7453\n",
      "FN: 2211\tTP: 3313\n",
      "\n",
      "% Predicted delays/cancellations that were delayed/cancelled: 0.30772803269552296\n",
      "% Predicted non-delays/cancellations that were not delayed/cancelled: 0.8446676970633694\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=20, min_samples_split=10, min_samples_leaf=10, class_weight='balanced', random_state=100)\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = rfc.predict(X_train)\n",
    "y_test_pred = rfc.predict(X_test)\n",
    "c = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "get_metrics(y_train, y_train_pred, y_test, y_test_pred, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* Our training and testing accuracy have both increased from the previous model and have stayed roughly equal to each other. \n",
    "* Slightly more of our positive predictions are correct, but the percentage is still very low.\n",
    "* Our negative predictions are roughly as accurate as they were in the previous model.\n",
    "\n",
    "This model is the best performing decision-tree based model among those we have built. However, we still face the issue that most of our positive predictions are wrong. We will build another type of model, a logistic regression model, and compare performance to see if we can obtain better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nnetznik\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\nnetznik\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\nnetznik\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\nnetznik\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\nnetznik\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\nnetznik\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\nnetznik\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\nnetznik\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\nnetznik\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\nnetznik\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\nnetznik\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\nnetznik\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\nnetznik\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\nnetznik\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\nnetznik\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "C:\\Users\\nnetznik\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\nnetznik\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\nnetznik\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'class_weight': 'balanced', 'fit_intercept': False, 'solver': 'lbfgs'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_grid = LogisticRegression()\n",
    "\n",
    "param_grid_logreg = {\n",
    "    'fit_intercept':[True, False],\n",
    "    'class_weight':['balanced'],\n",
    "    'solver':['liblinear', 'newton-cg', 'sag', 'saga', 'lbfgs'],\n",
    "     max_iter=1000\n",
    "}\n",
    "\n",
    "gs_logreg = GridSearchCV(logreg_grid, param_grid_logreg, cv=3, scoring='f1')\n",
    "gs_logreg.fit(X_train, y_train)\n",
    "\n",
    "gs_logreg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nnetznik\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6049333333333333\n",
      "Test accuracy:  0.60372\n",
      "\n",
      "TN: 11683\tFP:7793\n",
      "FN: 2114\tTP: 3410\n",
      "\n",
      "% Predicted delays/cancellations that were delayed/cancelled: 0.3043827546192984\n",
      "% Predicted non-delays/cancellations that were not delayed/cancelled: 0.8467782851344495\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(fit_intercept=False, \n",
    "                            class_weight='balanced',\n",
    "                            solver='lbfgs',\n",
    "                            max_iter=100)\n",
    "\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred = logreg.predict(X_train)\n",
    "y_test_pred = logreg.predict(X_test)\n",
    "c = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "get_metrics(y_train, y_train_pred, y_test, y_test_pred, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
