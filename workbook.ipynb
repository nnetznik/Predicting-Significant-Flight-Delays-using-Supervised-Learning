{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Significant Flight Delays using Supervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I present my work in ___________________________."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many consultants travel frequently over long distances for business purposes. Managers at a consulting firm might be interested in how to minimize -------------------------- risk when booking flights. One pertinent concern for these managers is how to reduce the risk of significant flight delay to ensure that consultants can utilize air travel reliably and efficiently.\n",
    "\n",
    "My goal is to predict whether a given flight will be significantly delayed given several known factors about the flight such as airline, scheduled time of departure, and ---------------------------------. An effective model of this kind will assist managers in understanding ---------------------- so that they can make more informed decisions when booking flights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This element assesses how well students demonstrate the utility of their data for helping solve a business\n",
    "problem. We frame utility in terms of the properties, source, and business relevance of the data.\n",
    "* This element assesses the demonstration of the dataâ€™s utility, not the utility itself\n",
    "\n",
    "Data Understanding: Notebook clearly describes the source and properties of the data to show how useful the data are for solving the problem of interest.\n",
    "* Describe the data sources and explain why the data are suitable for the project\n",
    "* Present the size of the dataset and descriptive statistics for all features used in the analysis\n",
    "* Justify the inclusion of features based on their properties and relevance for the project\n",
    "* Identify any limitations of the data that have implications for the project\n",
    "------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I obtained data for use by the public domain from https://www.kaggle.com/datasets/robikscube/flight-delay-dataset-20182022. Each row pertains to a flight --------------------. The data includes several promising features such as --------------------------------.\n",
    "\n",
    "I will bulid my model using a random sample from a year's worth of raw data spanning from August 2021 to July 2022."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nnetznik\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3145: DtypeWarning: Columns (12,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df_original = pd.read_csv('sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_keep = ['Quarter',\n",
    "           'Month', 'DayOfWeek', 'Operating_Airline ',\n",
    "           'Origin', 'Dest',\n",
    "           'DepTimeBlk', 'ArrDel15', 'ArrTimeBlk', 'Cancelled', 'Distance']\n",
    "len(to_keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_original[to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   Quarter             100000 non-null  int64  \n",
      " 1   Month               100000 non-null  int64  \n",
      " 2   DayOfWeek           100000 non-null  int64  \n",
      " 3   Operating_Airline   100000 non-null  object \n",
      " 4   Origin              100000 non-null  object \n",
      " 5   Dest                100000 non-null  object \n",
      " 6   DepTimeBlk          100000 non-null  object \n",
      " 7   ArrDel15            97266 non-null   float64\n",
      " 8   ArrTimeBlk          100000 non-null  object \n",
      " 9   Cancelled           100000 non-null  float64\n",
      " 10  Distance            100000 non-null  float64\n",
      "dtypes: float64(3), int64(3), object(5)\n",
      "memory usage: 8.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-76bca67eafed>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['Target'] = 0\n",
      "C:\\Users\\nnetznik\\Anaconda3\\envs\\learn-env\\lib\\site-packages\\pandas\\core\\frame.py:4163: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "# Create target variable - 1 if flight is significantly delayed, 0 if not\n",
    "df['Target'] = 0\n",
    "for idx, row in df.iterrows():\n",
    "    if row['ArrDel15'] == 1 or row['Cancelled'] == 1:\n",
    "        df.at[idx, 'Target'] = 1\n",
    "df.drop(['ArrDel15','Cancelled'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Operating_Airline</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Dest</th>\n",
       "      <th>DepTimeBlk</th>\n",
       "      <th>ArrTimeBlk</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>9E</td>\n",
       "      <td>DTW</td>\n",
       "      <td>TYS</td>\n",
       "      <td>2000-2059</td>\n",
       "      <td>2200-2259</td>\n",
       "      <td>443.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>UA</td>\n",
       "      <td>DEN</td>\n",
       "      <td>FLL</td>\n",
       "      <td>0900-0959</td>\n",
       "      <td>1500-1559</td>\n",
       "      <td>1703.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>AA</td>\n",
       "      <td>PHX</td>\n",
       "      <td>MCO</td>\n",
       "      <td>1600-1659</td>\n",
       "      <td>2200-2259</td>\n",
       "      <td>1849.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>DL</td>\n",
       "      <td>SLC</td>\n",
       "      <td>ATL</td>\n",
       "      <td>0800-0859</td>\n",
       "      <td>1300-1359</td>\n",
       "      <td>1590.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>YV</td>\n",
       "      <td>IAH</td>\n",
       "      <td>DFW</td>\n",
       "      <td>1800-1859</td>\n",
       "      <td>1900-1959</td>\n",
       "      <td>224.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>WN</td>\n",
       "      <td>AUS</td>\n",
       "      <td>MDW</td>\n",
       "      <td>1300-1359</td>\n",
       "      <td>1500-1559</td>\n",
       "      <td>972.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>OO</td>\n",
       "      <td>BHM</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1500-1559</td>\n",
       "      <td>1700-1759</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>DL</td>\n",
       "      <td>SLC</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2100-2159</td>\n",
       "      <td>2200-2259</td>\n",
       "      <td>391.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>DL</td>\n",
       "      <td>ATL</td>\n",
       "      <td>BNA</td>\n",
       "      <td>2000-2059</td>\n",
       "      <td>2000-2059</td>\n",
       "      <td>214.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>YX</td>\n",
       "      <td>DCA</td>\n",
       "      <td>JFK</td>\n",
       "      <td>1700-1759</td>\n",
       "      <td>1900-1959</td>\n",
       "      <td>213.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Quarter  Month  DayOfWeek Operating_Airline  Origin Dest DepTimeBlk  \\\n",
       "0            1      2          5                 9E    DTW  TYS  2000-2059   \n",
       "1            1      1          2                 UA    DEN  FLL  0900-0959   \n",
       "2            1      1          7                 AA    PHX  MCO  1600-1659   \n",
       "3            3      8          2                 DL    SLC  ATL  0800-0859   \n",
       "4            4     11          2                 YV    IAH  DFW  1800-1859   \n",
       "...        ...    ...        ...                ...    ...  ...        ...   \n",
       "99995        4     11          3                 WN    AUS  MDW  1300-1359   \n",
       "99996        2      6          5                 OO    BHM  DEN  1500-1559   \n",
       "99997        2      4          5                 DL    SLC  DEN  2100-2159   \n",
       "99998        3      8          5                 DL    ATL  BNA  2000-2059   \n",
       "99999        1      1          7                 YX    DCA  JFK  1700-1759   \n",
       "\n",
       "      ArrTimeBlk  Distance  Target  \n",
       "0      2200-2259     443.0       0  \n",
       "1      1500-1559    1703.0       1  \n",
       "2      2200-2259    1849.0       0  \n",
       "3      1300-1359    1590.0       0  \n",
       "4      1900-1959     224.0       0  \n",
       "...          ...       ...     ...  \n",
       "99995  1500-1559     972.0       0  \n",
       "99996  1700-1759    1083.0       0  \n",
       "99997  2200-2259     391.0       0  \n",
       "99998  2000-2059     214.0       0  \n",
       "99999  1900-1959     213.0       0  \n",
       "\n",
       "[100000 rows x 10 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Distance</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>810</th>\n",
       "      <th>811</th>\n",
       "      <th>812</th>\n",
       "      <th>813</th>\n",
       "      <th>814</th>\n",
       "      <th>815</th>\n",
       "      <th>816</th>\n",
       "      <th>817</th>\n",
       "      <th>818</th>\n",
       "      <th>819</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>443.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1703.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1849.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1590.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>972.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>1083.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>391.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>214.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>213.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows Ã— 821 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Distance    0    1    2    3    4    5    6    7    8  ...  810  811  \\\n",
       "0         443.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "1        1703.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0   \n",
       "2        1849.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "3        1590.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "4         224.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "...         ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "99995     972.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  1.0   \n",
       "99996    1083.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...  0.0  0.0   \n",
       "99997     391.0  1.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "99998     214.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "99999     213.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0  0.0   \n",
       "\n",
       "       812  813  814  815  816  817  818  819  \n",
       "0      0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2      0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "3      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4      0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "99995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "99996  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "99997  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "99998  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "99999  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[100000 rows x 821 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "X = df.drop(['Target'], axis=1)\n",
    "y = df['Target']\n",
    "\n",
    "X_cat = X.drop(['Distance'], axis=1)\n",
    "X_num = X[['Distance']]\n",
    "\n",
    "ohe = OneHotEncoder(drop=\"first\", sparse=False)\n",
    "ohe.fit(X_cat)\n",
    "\n",
    "X_cat_ohe = pd.DataFrame(\n",
    "    data=ohe.transform(X_cat),\n",
    "    # columns=[{cat} for cat in ohe.categories_[][1:]],\n",
    "    index=X_cat.index\n",
    ")\n",
    "\n",
    "X_final = pd.concat([X_num, X_cat_ohe], axis=1)\n",
    "X_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 2, 3, 4], dtype=int64),\n",
       " array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12], dtype=int64),\n",
       " array([1, 2, 3, 4, 5, 6, 7], dtype=int64),\n",
       " array(['9E', 'AA', 'AS', 'B6', 'C5', 'DL', 'F9', 'G4', 'G7', 'HA', 'MQ',\n",
       "        'NK', 'OH', 'OO', 'PT', 'QX', 'UA', 'WN', 'YV', 'YX', 'ZW'],\n",
       "       dtype=object),\n",
       " array(['ABE', 'ABI', 'ABQ', 'ABR', 'ABY', 'ACK', 'ACT', 'ACV', 'ACY',\n",
       "        'ADQ', 'AEX', 'AGS', 'AKN', 'ALB', 'ALO', 'ALS', 'ALW', 'AMA',\n",
       "        'ANC', 'APN', 'ART', 'ASE', 'ATL', 'ATW', 'ATY', 'AUS', 'AVL',\n",
       "        'AVP', 'AZA', 'AZO', 'BDL', 'BET', 'BFF', 'BFL', 'BGM', 'BGR',\n",
       "        'BHM', 'BIH', 'BIL', 'BIS', 'BJI', 'BKG', 'BLI', 'BLV', 'BMI',\n",
       "        'BNA', 'BOI', 'BOS', 'BPT', 'BQK', 'BQN', 'BRD', 'BRO', 'BRW',\n",
       "        'BTM', 'BTR', 'BTV', 'BUF', 'BUR', 'BWI', 'BZN', 'CAE', 'CAK',\n",
       "        'CDB', 'CDC', 'CDV', 'CGI', 'CHA', 'CHO', 'CHS', 'CID', 'CIU',\n",
       "        'CKB', 'CLE', 'CLL', 'CLT', 'CMH', 'CMI', 'CMX', 'CNY', 'COD',\n",
       "        'COS', 'COU', 'CPR', 'CRP', 'CRW', 'CSG', 'CVG', 'CWA', 'CYS',\n",
       "        'DAB', 'DAL', 'DAY', 'DBQ', 'DCA', 'DDC', 'DEC', 'DEN', 'DFW',\n",
       "        'DHN', 'DIK', 'DLG', 'DLH', 'DRO', 'DRT', 'DSM', 'DTW', 'DVL',\n",
       "        'EAR', 'EAT', 'EAU', 'ECP', 'EGE', 'EKO', 'ELM', 'ELP', 'ERI',\n",
       "        'ESC', 'EUG', 'EVV', 'EWN', 'EWR', 'EYW', 'FAI', 'FAR', 'FAT',\n",
       "        'FAY', 'FCA', 'FLG', 'FLL', 'FLO', 'FNT', 'FOD', 'FSD', 'FSM',\n",
       "        'FWA', 'GCC', 'GCK', 'GEG', 'GFK', 'GGG', 'GJT', 'GNV', 'GPT',\n",
       "        'GRB', 'GRI', 'GRK', 'GRR', 'GSO', 'GSP', 'GST', 'GTF', 'GTR',\n",
       "        'GUC', 'GUM', 'HDN', 'HHH', 'HIB', 'HLN', 'HNL', 'HOB', 'HOU',\n",
       "        'HPN', 'HRL', 'HSV', 'HTS', 'HYA', 'HYS', 'IAD', 'IAG', 'IAH',\n",
       "        'ICT', 'IDA', 'ILM', 'IMT', 'IND', 'INL', 'ISP', 'ITH', 'ITO',\n",
       "        'JAC', 'JAN', 'JAX', 'JFK', 'JLN', 'JMS', 'JNU', 'JST', 'KOA',\n",
       "        'KTN', 'LAN', 'LAR', 'LAS', 'LAW', 'LAX', 'LBB', 'LBE', 'LBF',\n",
       "        'LBL', 'LCH', 'LCK', 'LEX', 'LFT', 'LGA', 'LGB', 'LIH', 'LIT',\n",
       "        'LNK', 'LRD', 'LSE', 'LWB', 'LWS', 'LYH', 'MAF', 'MBS', 'MCI',\n",
       "        'MCO', 'MCW', 'MDT', 'MDW', 'MEI', 'MEM', 'MFE', 'MFR', 'MGM',\n",
       "        'MHK', 'MHT', 'MIA', 'MKE', 'MKG', 'MLB', 'MLI', 'MLU', 'MOB',\n",
       "        'MOT', 'MQT', 'MRY', 'MSN', 'MSO', 'MSP', 'MSY', 'MTJ', 'MVY',\n",
       "        'MYR', 'OAJ', 'OAK', 'OGD', 'OGG', 'OGS', 'OKC', 'OMA', 'OME',\n",
       "        'ONT', 'ORD', 'ORF', 'ORH', 'OTH', 'OTZ', 'OWB', 'PAE', 'PAH',\n",
       "        'PBG', 'PBI', 'PDX', 'PGD', 'PGV', 'PHF', 'PHL', 'PHX', 'PIA',\n",
       "        'PIB', 'PIE', 'PIH', 'PIR', 'PIT', 'PLN', 'PNS', 'PQI', 'PRC',\n",
       "        'PSC', 'PSE', 'PSG', 'PSM', 'PSP', 'PUB', 'PUW', 'PVD', 'PVU',\n",
       "        'PWM', 'RAP', 'RDD', 'RDM', 'RDU', 'RFD', 'RHI', 'RIC', 'RIW',\n",
       "        'RKS', 'RNO', 'ROA', 'ROC', 'ROW', 'RST', 'RSW', 'SAF', 'SAN',\n",
       "        'SAT', 'SAV', 'SBA', 'SBN', 'SBP', 'SBY', 'SCC', 'SCE', 'SCK',\n",
       "        'SDF', 'SEA', 'SFB', 'SFO', 'SGF', 'SGU', 'SHD', 'SHR', 'SHV',\n",
       "        'SIT', 'SJC', 'SJT', 'SJU', 'SLC', 'SLN', 'SMF', 'SMX', 'SNA',\n",
       "        'SPI', 'SPN', 'SPS', 'SRQ', 'STC', 'STL', 'STS', 'STT', 'STX',\n",
       "        'SUN', 'SUX', 'SWF', 'SWO', 'SYR', 'TBN', 'TLH', 'TOL', 'TPA',\n",
       "        'TRI', 'TTN', 'TUL', 'TUS', 'TVC', 'TWF', 'TXK', 'TYR', 'TYS',\n",
       "        'USA', 'VCT', 'VEL', 'VLD', 'VPS', 'WRG', 'WYS', 'XNA', 'XWA',\n",
       "        'YAK', 'YKM', 'YUM'], dtype=object),\n",
       " array(['ABE', 'ABI', 'ABQ', 'ABR', 'ABY', 'ACK', 'ACT', 'ACV', 'ACY',\n",
       "        'ADK', 'ADQ', 'AEX', 'AGS', 'AKN', 'ALB', 'ALO', 'ALS', 'ALW',\n",
       "        'AMA', 'ANC', 'APN', 'ART', 'ASE', 'ATL', 'ATW', 'ATY', 'AUS',\n",
       "        'AVL', 'AVP', 'AZA', 'AZO', 'BDL', 'BET', 'BFF', 'BFL', 'BGM',\n",
       "        'BGR', 'BHM', 'BIH', 'BIL', 'BIS', 'BJI', 'BKG', 'BLI', 'BLV',\n",
       "        'BMI', 'BNA', 'BOI', 'BOS', 'BPT', 'BQK', 'BQN', 'BRD', 'BRO',\n",
       "        'BRW', 'BTM', 'BTR', 'BTV', 'BUF', 'BUR', 'BWI', 'BZN', 'CAE',\n",
       "        'CAK', 'CDC', 'CDV', 'CGI', 'CHA', 'CHO', 'CHS', 'CID', 'CIU',\n",
       "        'CKB', 'CLE', 'CLL', 'CLT', 'CMH', 'CMI', 'CMX', 'CNY', 'COD',\n",
       "        'COS', 'COU', 'CPR', 'CRP', 'CRW', 'CSG', 'CVG', 'CWA', 'CYS',\n",
       "        'DAB', 'DAL', 'DAY', 'DBQ', 'DCA', 'DDC', 'DEC', 'DEN', 'DFW',\n",
       "        'DHN', 'DIK', 'DLG', 'DLH', 'DRO', 'DRT', 'DSM', 'DTW', 'DVL',\n",
       "        'EAR', 'EAT', 'EAU', 'ECP', 'EGE', 'EKO', 'ELM', 'ELP', 'ERI',\n",
       "        'ESC', 'EUG', 'EVV', 'EWN', 'EWR', 'EYW', 'FAI', 'FAR', 'FAT',\n",
       "        'FAY', 'FCA', 'FLG', 'FLL', 'FLO', 'FNT', 'FOD', 'FSD', 'FSM',\n",
       "        'FWA', 'GCC', 'GCK', 'GEG', 'GFK', 'GGG', 'GJT', 'GNV', 'GPT',\n",
       "        'GRB', 'GRI', 'GRK', 'GRR', 'GSO', 'GSP', 'GTF', 'GTR', 'GUC',\n",
       "        'GUM', 'HDN', 'HGR', 'HHH', 'HIB', 'HLN', 'HNL', 'HOB', 'HOU',\n",
       "        'HPN', 'HRL', 'HSV', 'HTS', 'HYA', 'HYS', 'IAD', 'IAG', 'IAH',\n",
       "        'ICT', 'IDA', 'ILG', 'ILM', 'IMT', 'IND', 'INL', 'IPT', 'ISP',\n",
       "        'ITH', 'ITO', 'JAC', 'JAN', 'JAX', 'JFK', 'JLN', 'JMS', 'JNU',\n",
       "        'JST', 'KOA', 'KTN', 'LAN', 'LAR', 'LAS', 'LAW', 'LAX', 'LBB',\n",
       "        'LBE', 'LBF', 'LBL', 'LCH', 'LCK', 'LEX', 'LFT', 'LGA', 'LGB',\n",
       "        'LIH', 'LIT', 'LNK', 'LRD', 'LSE', 'LWB', 'LWS', 'LYH', 'MAF',\n",
       "        'MBS', 'MCI', 'MCO', 'MCW', 'MDT', 'MDW', 'MEI', 'MEM', 'MFE',\n",
       "        'MFR', 'MGM', 'MHK', 'MHT', 'MIA', 'MKE', 'MKG', 'MLB', 'MLI',\n",
       "        'MLU', 'MOB', 'MOT', 'MQT', 'MRY', 'MSN', 'MSO', 'MSP', 'MSY',\n",
       "        'MTJ', 'MVY', 'MYR', 'OAJ', 'OAK', 'OGG', 'OGS', 'OKC', 'OMA',\n",
       "        'OME', 'ONT', 'ORD', 'ORF', 'ORH', 'OTH', 'OTZ', 'OWB', 'PAE',\n",
       "        'PAH', 'PBG', 'PBI', 'PDX', 'PGD', 'PGV', 'PHF', 'PHL', 'PHX',\n",
       "        'PIA', 'PIB', 'PIE', 'PIH', 'PIR', 'PIT', 'PLN', 'PNS', 'PPG',\n",
       "        'PQI', 'PRC', 'PSC', 'PSE', 'PSG', 'PSM', 'PSP', 'PUB', 'PUW',\n",
       "        'PVD', 'PVU', 'PWM', 'RAP', 'RDD', 'RDM', 'RDU', 'RFD', 'RHI',\n",
       "        'RIC', 'RIW', 'RKS', 'RNO', 'ROA', 'ROC', 'ROW', 'RST', 'RSW',\n",
       "        'SAF', 'SAN', 'SAT', 'SAV', 'SBA', 'SBN', 'SBP', 'SBY', 'SCC',\n",
       "        'SCE', 'SCK', 'SDF', 'SEA', 'SFB', 'SFO', 'SGF', 'SGU', 'SHD',\n",
       "        'SHR', 'SHV', 'SIT', 'SJC', 'SJT', 'SJU', 'SLC', 'SLN', 'SMF',\n",
       "        'SMX', 'SNA', 'SPI', 'SPN', 'SPS', 'SRQ', 'STC', 'STL', 'STS',\n",
       "        'STT', 'STX', 'SUN', 'SUX', 'SWF', 'SWO', 'SYR', 'TBN', 'TLH',\n",
       "        'TOL', 'TPA', 'TRI', 'TTN', 'TUL', 'TUS', 'TVC', 'TWF', 'TXK',\n",
       "        'TYR', 'TYS', 'USA', 'VCT', 'VEL', 'VLD', 'VPS', 'WRG', 'WYS',\n",
       "        'XNA', 'XWA', 'YAK', 'YKM', 'YUM'], dtype=object),\n",
       " array(['0001-0559', '0600-0659', '0700-0759', '0800-0859', '0900-0959',\n",
       "        '1000-1059', '1100-1159', '1200-1259', '1300-1359', '1400-1459',\n",
       "        '1500-1559', '1600-1659', '1700-1759', '1800-1859', '1900-1959',\n",
       "        '2000-2059', '2100-2159', '2200-2259', '2300-2359'], dtype=object),\n",
       " array(['0001-0559', '0600-0659', '0700-0759', '0800-0859', '0900-0959',\n",
       "        '1000-1059', '1100-1159', '1200-1259', '1300-1359', '1400-1459',\n",
       "        '1500-1559', '1600-1659', '1700-1759', '1800-1859', '1900-1959',\n",
       "        '2000-2059', '2100-2159', '2200-2259', '2300-2359'], dtype=object)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=100)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(criterion='entropy', random_state=100)\n",
    "\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6928\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_preds = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTODO:\\n- Figure out OHE issue with values showing up in testing that are not in training set\\n- Implement grid search for decision tree\\n- Consider using logistic regression\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "TODO:\n",
    "- Figure out OHE issue with values showing up in testing that are not in training set\n",
    "- Implement grid search for decision tree\n",
    "- Consider using logistic regression\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# clf_grid = DecisionTreeClassifier()\n",
    "\n",
    "# param_grid = {\n",
    "#     'criterion': ['gini', 'entropy'],\n",
    "#     'max_depth': [1, 5, 10, 20],\n",
    "#     'min_samples_split': [1.0, 2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 5, 10],\n",
    "#     'class_weight':['balanced']\n",
    "# }\n",
    "\n",
    "# gs_tree = GridSearchCV(clf_grid, param_grid, cv=3, scoring='f1')\n",
    "# gs_tree.fit(X_train, y_train)\n",
    "\n",
    "# gs_tree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.46444\n",
      "Train accuracy:  0.46758666666666665\n"
     ]
    }
   ],
   "source": [
    "clf_best = DecisionTreeClassifier(criterion='gini', max_depth=5, min_samples_split=5, min_samples_leaf=5, class_weight='balanced', random_state=100)\n",
    "clf_best.fit(X_train, y_train)\n",
    "y_preds_best = clf_best.predict(X_test)\n",
    "print('Test accuracy: ', accuracy_score(y_test, y_preds_best))\n",
    "print('Train accuracy: ', accuracy_score(y_train, clf_best.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "c = confusion_matrix(y_test, y_preds_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 4256\n",
      "TN:7355\n",
      "FP:12121\n",
      "FN:1268\n"
     ]
    }
   ],
   "source": [
    "print(\"TP: {}\\nTN:{}\\nFP:{}\\nFN:{}\".format(c[1][1], c[0][0], c[0][1], c[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of delayed/cancelled accurately predicted: 77.04561911658219%\n",
      "Percent of non-delayed/cancelled accurately predicted: 37.764428013965905%\n"
     ]
    }
   ],
   "source": [
    "print(\"Percent of delayed/cancelled accurately predicted: {}%\".format(c[1][1]/(c[1][1]+c[1][0])*100))\n",
    "print(\"Percent of non-delayed/cancelled accurately predicted: {}%\".format(c[0][0]/(c[0][0]+c[0][1])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of delayed/cancelled accurately predicted: 62.853005068790736%\n",
      "Percent of non-delayed/cancelled accurately predicted: 59.272951324707336%\n",
      "Test accuracy:  0.60064\n",
      "Train accuracy:  0.60208\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# X_train['Distance'] = X_train['Distance']/(max(X_train['Distance'])-min(X_train['Distance']))\n",
    "# X_test['Distance'] = X_test['Distance']/(max(X_test['Distance'])-min(X_test['Distance']))\n",
    "# Instantiate the model\n",
    "logreg = LogisticRegression(fit_intercept=False, \n",
    "                            # C=1e12,\n",
    "                            #solver='saga',\n",
    "                            class_weight='balanced',\n",
    "                           max_iter=1000)\n",
    "\n",
    "# Fit the model\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_hat_train = logreg.predict(X_train)\n",
    "y_hat_test = logreg.predict(X_test)\n",
    "\n",
    "c = confusion_matrix(y_test, y_hat_test)\n",
    "print(\"Percent of delayed/cancelled accurately predicted: {}%\".format(c[1][1]/(c[1][1]+c[1][0])*100))\n",
    "print(\"Percent of non-delayed/cancelled accurately predicted: {}%\".format(c[0][0]/(c[0][0]+c[0][1])*100))\n",
    "\n",
    "print('Test accuracy: ', accuracy_score(y_test, y_hat_test))\n",
    "print('Train accuracy: ', accuracy_score(y_train, y_hat_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# rfc_grid = RandomForestClassifier()\n",
    "\n",
    "# param_grid_rfc = {\n",
    "#     'n_estimators':[10],\n",
    "#     'criterion': ['gini', 'entropy'],\n",
    "#     'max_depth': [5, 10, 20],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [2, 5, 10],\n",
    "#     'class_weight':['balanced']\n",
    "# }\n",
    "\n",
    "# gs_rfc_tree = GridSearchCV(rfc_grid, param_grid_rfc, cv=3, scoring='f1')\n",
    "# gs_rfc_tree.fit(X_train, y_train)\n",
    "\n",
    "# gs_rfc_tree.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  0.61344\n",
      "Train accuracy:  0.46758666666666665\n",
      "Percent of delayed/cancelled accurately predicted: 59.974656046343235%\n",
      "Percent of non-delayed/cancelled accurately predicted: 61.73238858081742%\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators=10, criterion='gini', max_depth=20, min_samples_split=2, min_samples_leaf=10, class_weight='balanced', random_state=100)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_preds_best = rfc.predict(X_test)\n",
    "print('Test accuracy: ', accuracy_score(y_test, y_preds_best))\n",
    "print('Train accuracy: ', accuracy_score(y_train, clf_best.predict(X_train)))\n",
    "\n",
    "c = confusion_matrix(y_test, y_preds_best)\n",
    "\n",
    "print(\"Percent of delayed/cancelled accurately predicted: {}%\".format(c[1][1]/(c[1][1]+c[1][0])*100))\n",
    "print(\"Percent of non-delayed/cancelled accurately predicted: {}%\".format(c[0][0]/(c[0][0]+c[0][1])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12023,  7453],\n",
       "       [ 2211,  3313]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP: 3313\n",
      "TN:12023\n",
      "FP:7453\n",
      "FN:2211\n"
     ]
    }
   ],
   "source": [
    "print(\"TP: {}\\nTN:{}\\nFP:{}\\nFN:{}\".format(c[1][1], c[0][0], c[0][1], c[1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Consider eliminating rows with obscure airports (less than some count of total flights)?\n",
    "len(df.loc[df['Origin']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of delayed/cancelled accurately predicted: 17.23388848660391%\n",
      "Percent of non-delayed/cancelled accurately predicted: 94.13123844731977%\n",
      "Test accuracy:  0.7714\n",
      "Train accuracy:  0.76956\n"
     ]
    }
   ],
   "source": [
    "X_train_nb = X_train.drop(['Distance'], axis=1)\n",
    "X_test_nb = X_test.drop(['Distance'], axis=1)\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    " \n",
    "bnb = BernoulliNB()\n",
    "bnb.fit(X_train_nb, y_train)\n",
    "\n",
    "y_hat_train = bnb.predict(X_train_nb)\n",
    "y_hat_test = bnb.predict(X_test_nb)\n",
    "\n",
    "c = confusion_matrix(y_test, y_hat_test)\n",
    "print(\"Percent of delayed/cancelled accurately predicted: {}%\".format(c[1][1]/(c[1][1]+c[1][0])*100))\n",
    "print(\"Percent of non-delayed/cancelled accurately predicted: {}%\".format(c[0][0]/(c[0][0]+c[0][1])*100))\n",
    "\n",
    "print('Test accuracy: ', accuracy_score(y_test, y_hat_test))\n",
    "print('Train accuracy: ', accuracy_score(y_train, y_hat_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look into oversampling for naive bayes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
